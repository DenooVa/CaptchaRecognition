{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "import xlwt\n",
    "from xlwt import Workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import callbacks\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "10\n"
    }
   ],
   "source": [
    "symbols = '0123456789'\n",
    "num_symbols = len(symbols)\n",
    "img_shape = (50,135,1)\n",
    "print(num_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this block we difine our model\n",
    "def create_model():\n",
    "    img = layers.Input(shape=img_shape) \n",
    "    # Get image as an input and process it through some Convs\n",
    "    conv1 = layers.Conv2D(16, (3, 3), padding='same', activation='relu')(img)\n",
    "    mp1 = layers.MaxPooling2D(padding='same')(conv1)  # 100x25\n",
    "    conv2 = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(mp1)\n",
    "    mp2 = layers.MaxPooling2D(padding='same')(conv2)  # 50x13\n",
    "    conv3 = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(mp2)\n",
    "    bn = layers.BatchNormalization()(conv3)\n",
    "    mp3 = layers.MaxPooling2D(padding='same')(bn)  # 25x7\n",
    "    \n",
    "    # Get flattened vector and make 5 branches from it.\n",
    "    #Each branch will predict one letter\n",
    "    flat = layers.Flatten()(mp3)\n",
    "    outs = []\n",
    "    for _ in range(5):\n",
    "        dens1 = layers.Dense(64, activation='relu')(flat)\n",
    "        drop = layers.Dropout(0.5)(dens1)\n",
    "        res = layers.Dense(num_symbols, activation='sigmoid')(drop)\n",
    "\n",
    "        outs.append(res)\n",
    "    \n",
    "    # Compile model and return it\n",
    "    model = Model(img, outs)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove lines from image by dilation && closing && blur\n",
    "#def image_manipulation(dir):\n",
    "    # reading the image from file\n",
    "    #img = cv2.imread(dir,0) \n",
    "    # we need a kernel\n",
    "    #kernel = np.ones((3,3),np.uint8)\n",
    "    # dilate\n",
    "    #dilate = cv2.morphologyEx(img,cv2.MORPH_DILATE,kernel)\n",
    "    # close\n",
    "    #close = cv2.morphologyEx(img,cv2.MORPH_CLOSE,kernel)\n",
    "    # bilateral on close an dilate for 2 times\n",
    "    #blur_close = cv2.bilateralFilter(close,9,75,75)\n",
    "    #blur_dilate = cv2.bilateralFilter(dilate,9,75,75)\n",
    "    #blur2_dilate = cv2.bilateralFilter(blur_dilate,9,75,75)\n",
    "    #blur2_close = cv2.bilateralFilter(blur_close,9,75,75)\n",
    "    # original image\n",
    "    #cv2.imshow('image',img)\n",
    "    #cv2.imshow('close',close)\n",
    "    #cv2.imshow('dilate',dilate)\n",
    "    #cv2.imshow('blur2_close',blur2_close)\n",
    "    #cv2.imshow('blur2_dilate',blur2_dilate)\n",
    "    #cv2.imshow('thresh on blur2_close',thresh)\n",
    "    #cv2.waitKey(0)\n",
    "    #cv2.destroyAllWindows()\n",
    "    #return blur2_close,blur2_dilate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving those manipulated images\n",
    "#a = os.listdir()\n",
    "#b = os.listdir('captcha')\n",
    "#for i in range(0,len(b)):\n",
    "    #c , d = image_manipulation('captcha/'+ b[i])\n",
    "    #cv2.imwrite('blur2close/'+'_blur2close_'+b[i],c)\n",
    "    #cv2.imwrite('blur2dilate/'+'_blur2dilate_'+b[i],d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using blur2close + blur2dilate + captcha instead of just captcha\n",
    "def preprocess_data():\n",
    "    n_samples = len(os.listdir('All'))\n",
    "    X = np.zeros((n_samples, 50, 135, 1))\n",
    "    y = np.zeros((5, n_samples, num_symbols))\n",
    "\n",
    "    for i, pic in enumerate(os.listdir('All')):\n",
    "        # Read image as grayscale\n",
    "        img = cv2.imread(os.path.join('All/', pic), cv2.IMREAD_GRAYSCALE)\n",
    "        pic_target = pic[:-4]\n",
    "        if len(pic_target) < 6:\n",
    "            # Scale and reshape image\n",
    "            img = img / 255.0\n",
    "            img = np.reshape(img, (50, 135, 1))\n",
    "            # Define targets and code them using OneHotEncoding\n",
    "            targs = np.zeros((5, num_symbols))\n",
    "            for j, l in enumerate(pic_target):\n",
    "                ind = symbols.find(l)\n",
    "                targs[j, ind] = 1\n",
    "            X[i] = img\n",
    "            y[:, i] = targs\n",
    "    \n",
    "    # Return final data\n",
    "    return X, y\n",
    "\n",
    "X, y = preprocess_data()\n",
    "X_train, y_train = X[:970], y[:, :970]\n",
    "X_test, y_test = X[970:], y[:, 970:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 50, 135, 1)] 0                                            \n__________________________________________________________________________________________________\nconv2d (Conv2D)                 (None, 50, 135, 16)  160         input_1[0][0]                    \n__________________________________________________________________________________________________\nmax_pooling2d (MaxPooling2D)    (None, 25, 68, 16)   0           conv2d[0][0]                     \n__________________________________________________________________________________________________\nconv2d_1 (Conv2D)               (None, 25, 68, 32)   4640        max_pooling2d[0][0]              \n__________________________________________________________________________________________________\nmax_pooling2d_1 (MaxPooling2D)  (None, 13, 34, 32)   0           conv2d_1[0][0]                   \n__________________________________________________________________________________________________\nconv2d_2 (Conv2D)               (None, 13, 34, 32)   9248        max_pooling2d_1[0][0]            \n__________________________________________________________________________________________________\nbatch_normalization (BatchNorma (None, 13, 34, 32)   128         conv2d_2[0][0]                   \n__________________________________________________________________________________________________\nmax_pooling2d_2 (MaxPooling2D)  (None, 7, 17, 32)    0           batch_normalization[0][0]        \n__________________________________________________________________________________________________\nflatten (Flatten)               (None, 3808)         0           max_pooling2d_2[0][0]            \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 64)           243776      flatten[0][0]                    \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 64)           243776      flatten[0][0]                    \n__________________________________________________________________________________________________\ndense_4 (Dense)                 (None, 64)           243776      flatten[0][0]                    \n__________________________________________________________________________________________________\ndense_6 (Dense)                 (None, 64)           243776      flatten[0][0]                    \n__________________________________________________________________________________________________\ndense_8 (Dense)                 (None, 64)           243776      flatten[0][0]                    \n__________________________________________________________________________________________________\ndropout (Dropout)               (None, 64)           0           dense[0][0]                      \n__________________________________________________________________________________________________\ndropout_1 (Dropout)             (None, 64)           0           dense_2[0][0]                    \n__________________________________________________________________________________________________\ndropout_2 (Dropout)             (None, 64)           0           dense_4[0][0]                    \n__________________________________________________________________________________________________\ndropout_3 (Dropout)             (None, 64)           0           dense_6[0][0]                    \n__________________________________________________________________________________________________\ndropout_4 (Dropout)             (None, 64)           0           dense_8[0][0]                    \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 10)           650         dropout[0][0]                    \n__________________________________________________________________________________________________\ndense_3 (Dense)                 (None, 10)           650         dropout_1[0][0]                  \n__________________________________________________________________________________________________\ndense_5 (Dense)                 (None, 10)           650         dropout_2[0][0]                  \n__________________________________________________________________________________________________\ndense_7 (Dense)                 (None, 10)           650         dropout_3[0][0]                  \n__________________________________________________________________________________________________\ndense_9 (Dense)                 (None, 10)           650         dropout_4[0][0]                  \n==================================================================================================\nTotal params: 1,236,306\nTrainable params: 1,236,242\nNon-trainable params: 64\n__________________________________________________________________________________________________\n"
    }
   ],
   "source": [
    "model=create_model();\n",
    "model.summary();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "cy: 0.0000e+00 - val_dense_7_accuracy: 0.0000e+00 - val_dense_9_accuracy: 0.0000e+00\nEpoch 32/60\n134/134 [==============================] - 1s 5ms/sample - loss: 1.1945 - dense_1_loss: 0.1970 - dense_3_loss: 0.3012 - dense_5_loss: 0.1874 - dense_7_loss: 0.1492 - dense_9_loss: 0.3401 - dense_1_accuracy: 0.3657 - dense_3_accuracy: 0.3433 - dense_5_accuracy: 0.3806 - dense_7_accuracy: 0.4179 - dense_9_accuracy: 0.3209 - val_loss: 0.0000e+00 - val_dense_1_loss: 0.0000e+00 - val_dense_3_loss: 0.0000e+00 - val_dense_5_loss: 0.0000e+00 - val_dense_7_loss: 0.0000e+00 - val_dense_9_loss: 0.0000e+00 - val_dense_1_accuracy: 0.0000e+00 - val_dense_3_accuracy: 0.0000e+00 - val_dense_5_accuracy: 0.0000e+00 - val_dense_7_accuracy: 0.0000e+00 - val_dense_9_accuracy: 0.0000e+00\nEpoch 33/60\n134/134 [==============================] - 1s 4ms/sample - loss: 1.0429 - dense_1_loss: 0.2186 - dense_3_loss: 0.2050 - dense_5_loss: 0.1548 - dense_7_loss: 0.1599 - dense_9_loss: 0.2650 - dense_1_accuracy: 0.3731 - dense_3_accuracy: 0.3358 - dense_5_accuracy: 0.3806 - dense_7_accuracy: 0.3955 - dense_9_accuracy: 0.3582 - val_loss: 0.0000e+00 - val_dense_1_loss: 0.0000e+00 - val_dense_3_loss: 0.0000e+00 - val_dense_5_loss: 0.0000e+00 - val_dense_7_loss: 0.0000e+00 - val_dense_9_loss: 0.0000e+00 - val_dense_1_accuracy: 0.0000e+00 - val_dense_3_accuracy: 0.0000e+00 - val_dense_5_accuracy: 0.0000e+00 - val_dense_7_accuracy: 0.0000e+00 - val_dense_9_accuracy: 0.0000e+00\nEpoch 34/60\n134/134 [==============================] - 0s 4ms/sample - loss: 0.8349 - dense_1_loss: 0.1711 - dense_3_loss: 0.1556 - dense_5_loss: 0.1079 - dense_7_loss: 0.1645 - dense_9_loss: 0.1772 - dense_1_accuracy: 0.3433 - dense_3_accuracy: 0.4030 - dense_5_accuracy: 0.3806 - dense_7_accuracy: 0.3881 - dense_9_accuracy: 0.3582 - val_loss: 0.0000e+00 - val_dense_1_loss: 0.0000e+00 - val_dense_3_loss: 0.0000e+00 - val_dense_5_loss: 0.0000e+00 - val_dense_7_loss: 0.0000e+00 - val_dense_9_loss: 0.0000e+00 - val_dense_1_accuracy: 0.0000e+00 - val_dense_3_accuracy: 0.0000e+00 - val_dense_5_accuracy: 0.0000e+00 - val_dense_7_accuracy: 0.0000e+00 - val_dense_9_accuracy: 0.0000e+00\nEpoch 35/60\n134/134 [==============================] - 0s 4ms/sample - loss: 1.0588 - dense_1_loss: 0.1711 - dense_3_loss: 0.2755 - dense_5_loss: 0.1203 - dense_7_loss: 0.1700 - dense_9_loss: 0.2345 - dense_1_accuracy: 0.3731 - dense_3_accuracy: 0.3209 - dense_5_accuracy: 0.3657 - dense_7_accuracy: 0.3806 - dense_9_accuracy: 0.3433 - val_loss: 0.0000e+00 - val_dense_1_loss: 0.0000e+00 - val_dense_3_loss: 0.0000e+00 - val_dense_5_loss: 0.0000e+00 - val_dense_7_loss: 0.0000e+00 - val_dense_9_loss: 0.0000e+00 - val_dense_1_accuracy: 0.0000e+00 - val_dense_3_accuracy: 0.0000e+00 - val_dense_5_accuracy: 0.0000e+00 - val_dense_7_accuracy: 0.0000e+00 - val_dense_9_accuracy: 0.0000e+00\nEpoch 36/60\n134/134 [==============================] - 0s 2ms/sample - loss: 0.9919 - dense_1_loss: 0.1546 - dense_3_loss: 0.2673 - dense_5_loss: 0.1564 - dense_7_loss: 0.2060 - dense_9_loss: 0.2521 - dense_1_accuracy: 0.3881 - dense_3_accuracy: 0.3955 - dense_5_accuracy: 0.3507 - dense_7_accuracy: 0.3881 - dense_9_accuracy: 0.3806 - val_loss: 0.0000e+00 - val_dense_1_loss: 0.0000e+00 - val_dense_3_loss: 0.0000e+00 - val_dense_5_loss: 0.0000e+00 - val_dense_7_loss: 0.0000e+00 - val_dense_9_loss: 0.0000e+00 - val_dense_1_accuracy: 0.0000e+00 - val_dense_3_accuracy: 0.0000e+00 - val_dense_5_accuracy: 0.0000e+00 - val_dense_7_accuracy: 0.0000e+00 - val_dense_9_accuracy: 0.0000e+00\nEpoch 37/60\n134/134 [==============================] - 0s 3ms/sample - loss: 0.8098 - dense_1_loss: 0.1548 - dense_3_loss: 0.1619 - dense_5_loss: 0.0944 - dense_7_loss: 0.1844 - dense_9_loss: 0.2496 - dense_1_accuracy: 0.3806 - dense_3_accuracy: 0.3955 - dense_5_accuracy: 0.4179 - dense_7_accuracy: 0.3806 - dense_9_accuracy: 0.3433 - val_loss: 0.0000e+00 - val_dense_1_loss: 0.0000e+00 - val_dense_3_loss: 0.0000e+00 - val_dense_5_loss: 0.0000e+00 - val_dense_7_loss: 0.0000e+00 - val_dense_9_loss: 0.0000e+00 - val_dense_1_accuracy: 0.0000e+00 - val_dense_3_accuracy: 0.0000e+00 - val_dense_5_accuracy: 0.0000e+00 - val_dense_7_accuracy: 0.0000e+00 - val_dense_9_accuracy: 0.0000e+00\nEpoch 38/60\n134/134 [==============================] - 1s 4ms/sample - loss: 0.9516 - dense_1_loss: 0.1526 - dense_3_loss: 0.1973 - dense_5_loss: 0.0667 - dense_7_loss: 0.1402 - dense_9_loss: 0.2401 - dense_1_accuracy: 0.3731 - dense_3_accuracy: 0.3582 - dense_5_accuracy: 0.3881 - dense_7_accuracy: 0.3881 - dense_9_accuracy: 0.3209 - val_loss: 0.0000e+00 - val_dense_1_loss: 0.0000e+00 - val_dense_3_loss: 0.0000e+00 - val_dense_5_loss: 0.0000e+00 - val_dense_7_loss: 0.0000e+00 - val_dense_9_loss: 0.0000e+00 - val_dense_1_accuracy: 0.0000e+00 - val_dense_3_accuracy: 0.0000e+00 - val_dense_5_accuracy: 0.0000e+00 - val_dense_7_accuracy: 0.0000e+00 - val_dense_9_accuracy: 0.0000e+00\nEpoch 39/60\n134/134 [==============================] - 1s 4ms/sample - loss: 0.8770 - dense_1_loss: 0.1052 - dense_3_loss: 0.2953 - dense_5_loss: 0.1168 - dense_7_loss: 0.1046 - dense_9_loss: 0.1805 - dense_1_accuracy: 0.3881 - dense_3_accuracy: 0.3507 - dense_5_accuracy: 0.3955 - dense_7_accuracy: 0.4104 - dense_9_accuracy: 0.3731 - val_loss: 0.0000e+00 - val_dense_1_loss: 0.0000e+00 - val_dense_3_loss: 0.0000e+00 - val_dense_5_loss: 0.0000e+00 - val_dense_7_loss: 0.0000e+00 - val_dense_9_loss: 0.0000e+00 - val_dense_1_accuracy: 0.0000e+00 - val_dense_3_accuracy: 0.0000e+00 - val_dense_5_accuracy: 0.0000e+00 - val_dense_7_accuracy: 0.0000e+00 - val_dense_9_accuracy: 0.0000e+00\nEpoch 40/60\n134/134 [==============================] - 0s 3ms/sample - loss: 0.8407 - dense_1_loss: 0.1520 - dense_3_loss: 0.2710 - dense_5_loss: 0.1144 - dense_7_loss: 0.1221 - dense_9_loss: 0.1997 - dense_1_accuracy: 0.3657 - dense_3_accuracy: 0.3806 - dense_5_accuracy: 0.4104 - dense_7_accuracy: 0.3955 - dense_9_accuracy: 0.4030 - val_loss: 0.0000e+00 - val_dense_1_loss: 0.0000e+00 - val_dense_3_loss: 0.0000e+00 - val_dense_5_loss: 0.0000e+00 - val_dense_7_loss: 0.0000e+00 - val_dense_9_loss: 0.0000e+00 - val_dense_1_accuracy: 0.0000e+00 - val_dense_3_accuracy: 0.0000e+00 - val_dense_5_accuracy: 0.0000e+00 - val_dense_7_accuracy: 0.0000e+00 - val_dense_9_accuracy: 0.0000e+00\nEpoch 41/60\n134/134 [==============================] - 0s 3ms/sample - loss: 0.7986 - dense_1_loss: 0.1345 - dense_3_loss: 0.3626 - dense_5_loss: 0.3717 - dense_7_loss: 0.0711 - dense_9_loss: 0.1588 - dense_1_accuracy: 0.3881 - dense_3_accuracy: 0.3881 - dense_5_accuracy: 0.3731 - dense_7_accuracy: 0.4030 - dense_9_accuracy: 0.3507 - val_loss: 0.0000e+00 - val_dense_1_loss: 0.0000e+00 - val_dense_3_loss: 0.0000e+00 - val_dense_5_loss: 0.0000e+00 - val_dense_7_loss: 0.0000e+00 - val_dense_9_loss: 0.0000e+00 - val_dense_1_accuracy: 0.0000e+00 - val_dense_3_accuracy: 0.0000e+00 - val_dense_5_accuracy: 0.0000e+00 - val_dense_7_accuracy: 0.0000e+00 - val_dense_9_accuracy: 0.0000e+00\nEpoch 42/60\n134/134 [==============================] - 0s 3ms/sample - loss: 0.7332 - dense_1_loss: 0.1059 - dense_3_loss: 0.2271 - dense_5_loss: 0.0739 - dense_7_loss: 0.1141 - dense_9_loss: 0.2316 - dense_1_accuracy: 0.4030 - dense_3_accuracy: 0.4030 - dense_5_accuracy: 0.4104 - dense_7_accuracy: 0.4104 - dense_9_accuracy: 0.3507 - val_loss: 0.0000e+00 - val_dense_1_loss: 0.0000e+00 - val_dense_3_loss: 0.0000e+00 - val_dense_5_loss: 0.0000e+00 - val_dense_7_loss: 0.0000e+00 - val_dense_9_loss: 0.0000e+00 - val_dense_1_accuracy: 0.0000e+00 - val_dense_3_accuracy: 0.0000e+00 - val_dense_5_accuracy: 0.0000e+00 - val_dense_7_accuracy: 0.0000e+00 - val_dense_9_accuracy: 0.0000e+00\nEpoch 43/60\n134/134 [==============================] - 0s 3ms/sample - loss: 0.7660 - dense_1_loss: 0.2207 - dense_3_loss: 0.1909 - dense_5_loss: 0.0969 - dense_7_loss: 0.0937 - dense_9_loss: 0.1546 - dense_1_accuracy: 0.3881 - dense_3_accuracy: 0.3657 - dense_5_accuracy: 0.4030 - dense_7_accuracy: 0.3955 - dense_9_accuracy: 0.4179 - val_loss: 0.0000e+00 - val_dense_1_loss: 0.0000e+00 - val_dense_3_loss: 0.0000e+00 - val_dense_5_loss: 0.0000e+00 - val_dense_7_loss: 0.0000e+00 - val_dense_9_loss: 0.0000e+00 - val_dense_1_accuracy: 0.0000e+00 - val_dense_3_accuracy: 0.0000e+00 - val_dense_5_accuracy: 0.0000e+00 - val_dense_7_accuracy: 0.0000e+00 - val_dense_9_accuracy: 0.0000e+00\nEpoch 44/60\n134/134 [==============================] - 1s 4ms/sample - loss: 0.7470 - dense_1_loss: 0.1545 - dense_3_loss: 0.3111 - dense_5_loss: 0.0905 - dense_7_loss: 0.2041 - dense_9_loss: 0.1530 - dense_1_accuracy: 0.3731 - dense_3_accuracy: 0.3806 - dense_5_accuracy: 0.3955 - dense_7_accuracy: 0.3881 - dense_9_accuracy: 0.4627 - val_loss: 0.0000e+00 - val_dense_1_loss: 0.0000e+00 - val_dense_3_loss: 0.0000e+00 - val_dense_5_loss: 0.0000e+00 - val_dense_7_loss: 0.0000e+00 - val_dense_9_loss: 0.0000e+00 - val_dense_1_accuracy: 0.0000e+00 - val_dense_3_accuracy: 0.0000e+00 - val_dense_5_accuracy: 0.0000e+00 - val_dense_7_accuracy: 0.0000e+00 - val_dense_9_accuracy: 0.0000e+00\nEpoch 45/60\n134/134 [==============================] - 0s 3ms/sample - loss: 0.8922 - dense_1_loss: 0.1426 - dense_3_loss: 0.1250 - dense_5_loss: 0.2107 - dense_7_loss: 0.1399 - dense_9_loss: 0.2714 - dense_1_accuracy: 0.3806 - dense_3_accuracy: 0.4030 - dense_5_accuracy: 0.3582 - dense_7_accuracy: 0.3731 - dense_9_accuracy: 0.4104 - val_loss: 0.0000e+00 - val_dense_1_loss: 0.0000e+00 - val_dense_3_loss: 0.0000e+00 - val_dense_5_loss: 0.0000e+00 - val_dense_7_loss: 0.0000e+00 - val_dense_9_loss: 0.0000e+00 - val_dense_1_accuracy: 0.0000e+00 - val_dense_3_accuracy: 0.0000e+00 - val_dense_5_accuracy: 0.0000e+00 - val_dense_7_accuracy: 0.0000e+00 - val_dense_9_accuracy: 0.0000e+00\nEpoch 46/60\n134/134 [==============================] - 0s 3ms/sample - loss: 0.7576 - dense_1_loss: 0.1666 - dense_3_loss: 0.2151 - dense_5_loss: 0.0871 - dense_7_loss: 0.0859 - dense_9_loss: 0.1933 - dense_1_accuracy: 0.3806 - dense_3_accuracy: 0.3731 - dense_5_accuracy: 0.4104 - dense_7_accuracy: 0.4179 - dense_9_accuracy: 0.4254 - val_loss: 0.0000e+00 - val_dense_1_loss: 0.0000e+00 - val_dense_3_loss: 0.0000e+00 - val_dense_5_loss: 0.0000e+00 - val_dense_7_loss: 0.0000e+00 - val_dense_9_loss: 0.0000e+00 - val_dense_1_accuracy: 0.0000e+00 - val_dense_3_accuracy: 0.0000e+00 - val_dense_5_accuracy: 0.0000e+00 - val_dense_7_accuracy: 0.0000e+00 - val_dense_9_accuracy: 1.0000\nEpoch 47/60\n134/134 [==============================] - 0s 4ms/sample - loss: 0.5531 - dense_1_loss: 0.1267 - dense_3_loss: 0.1100 - dense_5_loss: 0.1112 - dense_7_loss: 0.0582 - dense_9_loss: 0.1402 - dense_1_accuracy: 0.3955 - dense_3_accuracy: 0.3881 - dense_5_accuracy: 0.4030 - dense_7_accuracy: 0.4104 - dense_9_accuracy: 0.4403 - val_loss: 0.0000e+00 - val_dense_1_loss: 0.0000e+00 - val_dense_3_loss: 0.0000e+00 - val_dense_5_loss: 0.0000e+00 - val_dense_7_loss: 0.0000e+00 - val_dense_9_loss: 0.0000e+00 - val_dense_1_accuracy: 0.0000e+00 - val_dense_3_accuracy: 0.0000e+00 - val_dense_5_accuracy: 0.0000e+00 - val_dense_7_accuracy: 0.0000e+00 - val_dense_9_accuracy: 1.0000\nEpoch 48/60\n134/134 [==============================] - 0s 3ms/sample - loss: 0.6717 - dense_1_loss: 0.0824 - dense_3_loss: 0.2076 - dense_5_loss: 0.1183 - dense_7_loss: 0.1387 - dense_9_loss: 0.0966 - dense_1_accuracy: 0.3806 - dense_3_accuracy: 0.3806 - dense_5_accuracy: 0.3806 - dense_7_accuracy: 0.3806 - dense_9_accuracy: 0.4478 - val_loss: 0.0000e+00 - val_dense_1_loss: 0.0000e+00 - val_dense_3_loss: 0.0000e+00 - val_dense_5_loss: 0.0000e+00 - val_dense_7_loss: 0.0000e+00 - val_dense_9_loss: 0.0000e+00 - val_dense_1_accuracy: 0.0000e+00 - val_dense_3_accuracy: 0.0000e+00 - val_dense_5_accuracy: 0.0000e+00 - val_dense_7_accuracy: 0.0000e+00 - val_dense_9_accuracy: 0.0000e+00\nEpoch 49/60\n134/134 [==============================] - 0s 3ms/sample - loss: 0.5480 - dense_1_loss: 0.0839 - dense_3_loss: 0.1036 - dense_5_loss: 0.0572 - dense_7_loss: 0.0646 - dense_9_loss: 0.1845 - dense_1_accuracy: 0.4030 - dense_3_accuracy: 0.3881 - dense_5_accuracy: 0.4104 - dense_7_accuracy: 0.4104 - dense_9_accuracy: 0.4403 - val_loss: 0.0000e+00 - val_dense_1_loss: 0.0000e+00 - val_dense_3_loss: 0.0000e+00 - val_dense_5_loss: 0.0000e+00 - val_dense_7_loss: 0.0000e+00 - val_dense_9_loss: 0.0000e+00 - val_dense_1_accuracy: 0.0000e+00 - val_dense_3_accuracy: 0.0000e+00 - val_dense_5_accuracy: 0.0000e+00 - val_dense_7_accuracy: 0.0000e+00 - val_dense_9_accuracy: 0.0000e+00\nEpoch 50/60\n134/134 [==============================] - 0s 3ms/sample - loss: 0.5927 - dense_1_loss: 0.1203 - dense_3_loss: 0.1287 - dense_5_loss: 0.1438 - dense_7_loss: 0.0522 - dense_9_loss: 0.1242 - dense_1_accuracy: 0.3955 - dense_3_accuracy: 0.3806 - dense_5_accuracy: 0.3657 - dense_7_accuracy: 0.4179 - dense_9_accuracy: 0.4328 - val_loss: 0.0000e+00 - val_dense_1_loss: 0.0000e+00 - val_dense_3_loss: 0.0000e+00 - val_dense_5_loss: 0.0000e+00 - val_dense_7_loss: 0.0000e+00 - val_dense_9_loss: 0.0000e+00 - val_dense_1_accuracy: 0.0000e+00 - val_dense_3_accuracy: 0.0000e+00 - val_dense_5_accuracy: 0.0000e+00 - val_dense_7_accuracy: 0.0000e+00 - val_dense_9_accuracy: 0.0000e+00\nEpoch 51/60\n134/134 [==============================] - 0s 4ms/sample - loss: 0.6306 - dense_1_loss: 0.1093 - dense_3_loss: 0.2356 - dense_5_loss: 0.0991 - dense_7_loss: 0.0809 - dense_9_loss: 0.1881 - dense_1_accuracy: 0.3881 - dense_3_accuracy: 0.3657 - dense_5_accuracy: 0.4030 - dense_7_accuracy: 0.4104 - dense_9_accuracy: 0.3955 - val_loss: 0.0000e+00 - val_dense_1_loss: 0.0000e+00 - val_dense_3_loss: 0.0000e+00 - val_dense_5_loss: 0.0000e+00 - val_dense_7_loss: 0.0000e+00 - val_dense_9_loss: 0.0000e+00 - val_dense_1_accuracy: 0.0000e+00 - val_dense_3_accuracy: 0.0000e+00 - val_dense_5_accuracy: 0.0000e+00 - val_dense_7_accuracy: 0.0000e+00 - val_dense_9_accuracy: 0.0000e+00\nEpoch 52/60\n134/134 [==============================] - 0s 3ms/sample - loss: 0.6657 - dense_1_loss: 0.1915 - dense_3_loss: 0.1549 - dense_5_loss: 0.0878 - dense_7_loss: 0.0919 - dense_9_loss: 0.1853 - dense_1_accuracy: 0.3881 - dense_3_accuracy: 0.4030 - dense_5_accuracy: 0.3955 - dense_7_accuracy: 0.4179 - dense_9_accuracy: 0.3881 - val_loss: 0.0000e+00 - val_dense_1_loss: 0.0000e+00 - val_dense_3_loss: 0.0000e+00 - val_dense_5_loss: 0.0000e+00 - val_dense_7_loss: 0.0000e+00 - val_dense_9_loss: 0.0000e+00 - val_dense_1_accuracy: 0.0000e+00 - val_dense_3_accuracy: 0.0000e+00 - val_dense_5_accuracy: 0.0000e+00 - val_dense_7_accuracy: 0.0000e+00 - val_dense_9_accuracy: 0.0000e+00\nEpoch 53/60\n134/134 [==============================] - 1s 4ms/sample - loss: 0.6133 - dense_1_loss: 0.1070 - dense_3_loss: 0.0914 - dense_5_loss: 0.1199 - dense_7_loss: 0.1166 - dense_9_loss: 0.1439 - dense_1_accuracy: 0.3955 - dense_3_accuracy: 0.4179 - dense_5_accuracy: 0.3955 - dense_7_accuracy: 0.4030 - dense_9_accuracy: 0.3731 - val_loss: 0.0000e+00 - val_dense_1_loss: 0.0000e+00 - val_dense_3_loss: 0.0000e+00 - val_dense_5_loss: 0.0000e+00 - val_dense_7_loss: 0.0000e+00 - val_dense_9_loss: 0.0000e+00 - val_dense_1_accuracy: 0.0000e+00 - val_dense_3_accuracy: 0.0000e+00 - val_dense_5_accuracy: 0.0000e+00 - val_dense_7_accuracy: 0.0000e+00 - val_dense_9_accuracy: 0.0000e+00\nEpoch 54/60\n134/134 [==============================] - 0s 3ms/sample - loss: 0.3940 - dense_1_loss: 0.0930 - dense_3_loss: 0.1467 - dense_5_loss: 0.0700 - dense_7_loss: 0.0601 - dense_9_loss: 0.1611 - dense_1_accuracy: 0.3955 - dense_3_accuracy: 0.4104 - dense_5_accuracy: 0.4030 - dense_7_accuracy: 0.4478 - dense_9_accuracy: 0.4030 - val_loss: 0.0000e+00 - val_dense_1_loss: 0.0000e+00 - val_dense_3_loss: 0.0000e+00 - val_dense_5_loss: 0.0000e+00 - val_dense_7_loss: 0.0000e+00 - val_dense_9_loss: 0.0000e+00 - val_dense_1_accuracy: 0.0000e+00 - val_dense_3_accuracy: 0.0000e+00 - val_dense_5_accuracy: 0.0000e+00 - val_dense_7_accuracy: 0.0000e+00 - val_dense_9_accuracy: 0.0000e+00\nEpoch 55/60\n134/134 [==============================] - 0s 3ms/sample - loss: 0.6076 - dense_1_loss: 0.1591 - dense_3_loss: 0.1185 - dense_5_loss: 0.1184 - dense_7_loss: 0.0910 - dense_9_loss: 0.0836 - dense_1_accuracy: 0.3881 - dense_3_accuracy: 0.3955 - dense_5_accuracy: 0.3806 - dense_7_accuracy: 0.4104 - dense_9_accuracy: 0.3955 - val_loss: 0.0000e+00 - val_dense_1_loss: 0.0000e+00 - val_dense_3_loss: 0.0000e+00 - val_dense_5_loss: 0.0000e+00 - val_dense_7_loss: 0.0000e+00 - val_dense_9_loss: 0.0000e+00 - val_dense_1_accuracy: 0.0000e+00 - val_dense_3_accuracy: 0.0000e+00 - val_dense_5_accuracy: 0.0000e+00 - val_dense_7_accuracy: 0.0000e+00 - val_dense_9_accuracy: 0.0000e+00\nEpoch 56/60\n134/134 [==============================] - 0s 4ms/sample - loss: 0.4716 - dense_1_loss: 0.1061 - dense_3_loss: 0.1329 - dense_5_loss: 0.0671 - dense_7_loss: 0.0512 - dense_9_loss: 0.0600 - dense_1_accuracy: 0.3955 - dense_3_accuracy: 0.3731 - dense_5_accuracy: 0.4104 - dense_7_accuracy: 0.4403 - dense_9_accuracy: 0.3955 - val_loss: 0.0000e+00 - val_dense_1_loss: 0.0000e+00 - val_dense_3_loss: 0.0000e+00 - val_dense_5_loss: 0.0000e+00 - val_dense_7_loss: 0.0000e+00 - val_dense_9_loss: 0.0000e+00 - val_dense_1_accuracy: 0.0000e+00 - val_dense_3_accuracy: 0.0000e+00 - val_dense_5_accuracy: 0.0000e+00 - val_dense_7_accuracy: 0.0000e+00 - val_dense_9_accuracy: 0.0000e+00\nEpoch 57/60\n134/134 [==============================] - 0s 4ms/sample - loss: 0.3620 - dense_1_loss: 0.0848 - dense_3_loss: 0.1012 - dense_5_loss: 0.0713 - dense_7_loss: 0.0590 - dense_9_loss: 0.0690 - dense_1_accuracy: 0.4030 - dense_3_accuracy: 0.4104 - dense_5_accuracy: 0.3955 - dense_7_accuracy: 0.4030 - dense_9_accuracy: 0.4328 - val_loss: 0.0000e+00 - val_dense_1_loss: 0.0000e+00 - val_dense_3_loss: 0.0000e+00 - val_dense_5_loss: 0.0000e+00 - val_dense_7_loss: 0.0000e+00 - val_dense_9_loss: 0.0000e+00 - val_dense_1_accuracy: 0.0000e+00 - val_dense_3_accuracy: 0.0000e+00 - val_dense_5_accuracy: 0.0000e+00 - val_dense_7_accuracy: 0.0000e+00 - val_dense_9_accuracy: 0.0000e+00\nEpoch 58/60\n134/134 [==============================] - 0s 3ms/sample - loss: 0.4604 - dense_1_loss: 0.0546 - dense_3_loss: 0.0743 - dense_5_loss: 0.0442 - dense_7_loss: 0.0919 - dense_9_loss: 0.1215 - dense_1_accuracy: 0.4179 - dense_3_accuracy: 0.3955 - dense_5_accuracy: 0.4179 - dense_7_accuracy: 0.3955 - dense_9_accuracy: 0.4179 - val_loss: 0.0000e+00 - val_dense_1_loss: 0.0000e+00 - val_dense_3_loss: 0.0000e+00 - val_dense_5_loss: 0.0000e+00 - val_dense_7_loss: 0.0000e+00 - val_dense_9_loss: 0.0000e+00 - val_dense_1_accuracy: 0.0000e+00 - val_dense_3_accuracy: 0.0000e+00 - val_dense_5_accuracy: 0.0000e+00 - val_dense_7_accuracy: 0.0000e+00 - val_dense_9_accuracy: 0.0000e+00\nEpoch 59/60\n134/134 [==============================] - 1s 4ms/sample - loss: 0.5080 - dense_1_loss: 0.0747 - dense_3_loss: 0.1340 - dense_5_loss: 0.0719 - dense_7_loss: 0.0774 - dense_9_loss: 0.1392 - dense_1_accuracy: 0.4179 - dense_3_accuracy: 0.3955 - dense_5_accuracy: 0.3806 - dense_7_accuracy: 0.4403 - dense_9_accuracy: 0.3806 - val_loss: 0.0000e+00 - val_dense_1_loss: 0.0000e+00 - val_dense_3_loss: 0.0000e+00 - val_dense_5_loss: 0.0000e+00 - val_dense_7_loss: 0.0000e+00 - val_dense_9_loss: 0.0000e+00 - val_dense_1_accuracy: 0.0000e+00 - val_dense_3_accuracy: 0.0000e+00 - val_dense_5_accuracy: 0.0000e+00 - val_dense_7_accuracy: 0.0000e+00 - val_dense_9_accuracy: 0.0000e+00\nEpoch 60/60\n134/134 [==============================] - 0s 3ms/sample - loss: 0.5866 - dense_1_loss: 0.0647 - dense_3_loss: 0.1671 - dense_5_loss: 0.0394 - dense_7_loss: 0.1528 - dense_9_loss: 0.1351 - dense_1_accuracy: 0.4104 - dense_3_accuracy: 0.3731 - dense_5_accuracy: 0.4030 - dense_7_accuracy: 0.4030 - dense_9_accuracy: 0.3806 - val_loss: 0.0000e+00 - val_dense_1_loss: 0.0000e+00 - val_dense_3_loss: 0.0000e+00 - val_dense_5_loss: 0.0000e+00 - val_dense_7_loss: 0.0000e+00 - val_dense_9_loss: 0.0000e+00 - val_dense_1_accuracy: 0.0000e+00 - val_dense_3_accuracy: 0.0000e+00 - val_dense_5_accuracy: 0.0000e+00 - val_dense_7_accuracy: 0.0000e+00 - val_dense_9_accuracy: 0.0000e+00\n"
    }
   ],
   "source": [
    "#model = create_model()\n",
    "hist = model.fit(X_train, [y_train[0], y_train[1], y_train[2], y_train[3], y_train[4]], batch_size=32, epochs=60,verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to predict captcha\n",
    "def predict(filepath):\n",
    "    img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is not None:\n",
    "        img = img / 255.0\n",
    "    else:\n",
    "        print(\"Not detected\");\n",
    "    res = np.array(model.predict(img[np.newaxis, :, :, np.newaxis]))\n",
    "    ans = np.reshape(res, (5, 10))\n",
    "    l_ind = []\n",
    "    probs = []\n",
    "    for a in ans:\n",
    "        l_ind.append(np.argmax(a))\n",
    "        #probs.append(np.max(a))\n",
    "\n",
    "    capt = ''\n",
    "    for l in l_ind:\n",
    "        capt += symbols[l]\n",
    "    return capt#, sum(probs) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "filename:13469.jpg , result is :  13469\ntrue\nfilename:13963.jpg , result is :  13963\ntrue\nfilename:16723.jpg , result is :  16723\ntrue\nfilename:18641.jpg , result is :  18641\ntrue\nfilename:18955.jpg , result is :  18955\ntrue\nfilename:21118.jpg , result is :  21118\ntrue\nfilename:21987.jpg , result is :  21987\ntrue\nfilename:24184.jpg , result is :  24184\ntrue\nfilename:26971.jpg , result is :  26971\ntrue\nfilename:27114.jpg , result is :  27114\ntrue\nfilename:28192.jpg , result is :  28192\ntrue\nfilename:33261.jpg , result is :  33261\ntrue\nfilename:34425.jpg , result is :  34425\ntrue\nfilename:35125.jpg , result is :  35125\ntrue\nfilename:35165.jpg , result is :  35165\ntrue\nfilename:36248.jpg , result is :  36248\ntrue\nfilename:37341.jpg , result is :  37341\ntrue\nfilename:37826.jpg , result is :  37826\ntrue\nfilename:37917.jpg , result is :  37917\ntrue\nfilename:39621.jpg , result is :  39621\ntrue\nfilename:39872.jpg , result is :  39872\ntrue\nfilename:42445.jpg , result is :  42445\ntrue\nfilename:43454.jpg , result is :  43454\ntrue\nfilename:43675.jpg , result is :  43675\ntrue\nfilename:44845.jpg , result is :  44845\ntrue\nfilename:45522.jpg , result is :  45522\ntrue\nfilename:48446.jpg , result is :  48446\ntrue\nfilename:53172.jpg , result is :  53172\ntrue\nfilename:54262.jpg , result is :  54262\ntrue\nfilename:56687.jpg , result is :  56687\ntrue\nfilename:58251.jpg , result is :  58251\ntrue\nfilename:61364.jpg , result is :  61364\ntrue\nfilename:61787.jpg , result is :  61787\ntrue\nfilename:65783.jpg , result is :  65783\ntrue\nfilename:66573.jpg , result is :  66573\ntrue\nfilename:67213.jpg , result is :  67213\ntrue\nfilename:67843.jpg , result is :  67843\ntrue\nfilename:71811.jpg , result is :  71811\ntrue\nfilename:71896.jpg , result is :  71896\ntrue\nfilename:74561.jpg , result is :  74561\ntrue\nfilename:75279.jpg , result is :  75279\ntrue\nfilename:75672.jpg , result is :  75672\ntrue\nfilename:75886.jpg , result is :  75886\ntrue\nfilename:76247.jpg , result is :  76247\ntrue\nfilename:77573.jpg , result is :  77573\ntrue\nfilename:78542.jpg , result is :  78542\ntrue\nfilename:79988.jpg , result is :  79988\ntrue\nfilename:81251.jpg , result is :  81251\ntrue\nfilename:82839.jpg , result is :  82839\ntrue\nfilename:84787.jpg , result is :  84787\ntrue\nfilename:86111.jpg , result is :  86111\ntrue\nfilename:87111.jpg , result is :  87111\ntrue\nfilename:91968.jpg , result is :  91968\ntrue\nfilename:94551.jpg , result is :  94551\ntrue\nfilename:99546.jpg , result is :  99546\ntrue\nfilename:99834.jpg , result is :  99834\ntrue\n"
    }
   ],
   "source": [
    "# in this block we predict the values\n",
    "wb = Workbook()\n",
    "sheet1 = wb.add_sheet('Sheet 1')\n",
    "sheet1.write(0, 0, 'name of the JPEG file')\n",
    "sheet1.write(0, 1, 'predicted value')\n",
    "sheet1.write(0, 2, 'true/false')\n",
    "a = os.listdir('test')\n",
    "positive = 0\n",
    "negetive = 0\n",
    "for i in range(0,56):\n",
    "    print(f\"filename:{a[i]} , result is : \",predict('test/'+a[i]))\n",
    "    # row start at 1 , column at 0\n",
    "    sheet1.write(i+1, 0, a[i])\n",
    "    sheet1.write(i+1, 1, predict('test/'+a[i])) \n",
    "    if a[i][0:5] == (predict('test/'+a[i])):\n",
    "        print('true')\n",
    "        positive = positive + 1\n",
    "        sheet1.write(i+1, 2, 'true')\n",
    "    else:\n",
    "        print('false')\n",
    "        negetive = negetive + 1\n",
    "        sheet1.write(i+1, 2, 'false')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "true cases:  56  false cases :  0\n"
    }
   ],
   "source": [
    "# see the number of true and false cases\n",
    "print('true cases: ',positive,' false cases : ',negetive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the excel file\n",
    "wb.save('xlswt result.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the result file\n",
    "os.startfile(\"xlswt result.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}